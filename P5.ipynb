{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "#from IPython.display import HTML\n",
    "\n",
    "#Returns the objpoints and imgpoints needed for undistortion\n",
    "def calibrate( images, nx = 6, ny = 9 ):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            \n",
    "    return objpoints, imgpoints\n",
    "\n",
    "#Uses the objpoints and imgponts from calibrate to undistort an image\n",
    "def undistort( img, objpoints, imgpoints ):\n",
    "    # Get the image size\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "    #Undistort the image\n",
    "    img_undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    return img_undist\n",
    "\n",
    "#Makes the image a single channel image\n",
    "#Can do gray, R, G, B, H, L, ans S\n",
    "def color_select(img, gray = False, hls=True, channel = 0):\n",
    "    # Return the gray channel if requested\n",
    "    if(gray):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        return img \n",
    "    # Convert to HLS color space if requested\n",
    "    if (hls):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # Return the selected channel\n",
    "    channelImage = img[:,:,channel]\n",
    "    \n",
    "    return channelImage\n",
    "\n",
    "\n",
    "#Does sobel 'x', 'y', 'mag', or 'dir' for rgb and grayscale images\n",
    "def sobel(img, type='x', sobel_kernel=3, rgb = True):\n",
    "    # Convert to grayscale, if necessary\n",
    "    if rgb:\n",
    "        gray = color_select(img, True)\n",
    "    else:\n",
    "        gray = image\n",
    "        \n",
    "    #Take the derivative in x and y \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    #Decide which sobel to return\n",
    "    if type == 'x':\n",
    "        sobel_image = sobelx\n",
    "    elif type == 'y':\n",
    "        sobel_image = sobely\n",
    "    elif type =='mag':\n",
    "        sobel_image = np.sqrt(np.power(sobelx, 2) + np.power(sobely, 2))\n",
    "    elif type == 'dir':\n",
    "        sobel_image = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    else:\n",
    "        return (none)\n",
    "        \n",
    "    # Always return a scaled image - 0 to 255\n",
    "    abs_sobel = np.absolute(sobel_image)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    return scaled_sobel\n",
    "\n",
    "# Thresholds a single channel image given an exclusive lower bound (>)\n",
    "# and inclusive upper (<=)\n",
    "def thresh(img, thresh=(0, 255)):\n",
    "    #Apply a threshold to the image channel\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img > thresh[0]) & (img <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    #binary_output = np.copy(binary) # placeholder line\n",
    "    return binary\n",
    "\n",
    "#Define the pipeline to get to a thresholded image\n",
    "def thresh_pipeline( image ):\n",
    "\n",
    "    #Threshold the R channel\n",
    "    rgb0 = color_select(image, hls=False, channel = 0)\n",
    "    rgb0_thresh = thresh(rgb0, thresh=(224, 255))\n",
    "\n",
    "    #Threshold the G channel\n",
    "    rgb1 = color_select(image, hls=False, channel = 1)\n",
    "    rgb1_thresh = thresh(rgb1, thresh=(200, 255))\n",
    "\n",
    "    #Threshold the L channel\n",
    "    hls1 = color_select(image, hls=True, channel = 1)\n",
    "    hls1_thresh = thresh(hls1, thresh=(192, 255))\n",
    "\n",
    "    #Threshold the B channel\n",
    "    hls2 = color_select(image, hls=True, channel = 2)\n",
    "    hls2_thresh = thresh(hls2, thresh=(192, 255))\n",
    "\n",
    "    all_colors = rgb0_thresh+rgb1_thresh+hls1_thresh+hls2_thresh\n",
    "    \n",
    "    #cv2.imwrite(\"image_all_colors.jpg\", all_colors*64)\n",
    "\n",
    "    #Threshold the X sobel\n",
    "    grad_x = sobel(image, type='x', sobel_kernel=5) # , thresh_min=5, thresh_max=100,\n",
    "    grad_binary_x = thresh(grad_x, thresh=(32, 192))\n",
    "\n",
    "    #Threshold the Y sobel\n",
    "    grad_y = sobel(image, type='y',  sobel_kernel=5)\n",
    "    grad_binary_y = thresh(grad_y, thresh=(32, 192))\n",
    "\n",
    "    #Threshold the sobel magnitude\n",
    "    grad_mag = sobel(image, type='mag', sobel_kernel=5) # , thresh_min=5, thresh_max=100,\n",
    "    grad_binary_mag = thresh(grad_mag, thresh=(64, 255))\n",
    "\n",
    "    #Threshold the sobel direction\n",
    "    grad_dir = sobel(image, type='dir',  sobel_kernel=5)\n",
    "    grad_binary_dir = thresh(grad_dir, thresh=(128, 255))\n",
    "\n",
    "    all_grad = grad_binary_dir+grad_binary_mag+grad_binary_x+grad_binary_y\n",
    "\n",
    "    #cv2.imwrite(\"image_all_grad.jpg\", all_grad*64)\n",
    "\n",
    "    #Color info is weighted 3x to gradient info\n",
    "    all_data = all_grad + all_colors*3\n",
    "\n",
    "    return all_data\n",
    "\n",
    "#Calculate the warping matrix\n",
    "def calcwarp(img, size = 300):\n",
    "    height = img.shape[0] # 720\n",
    "    width = img.shape[1] # 1280\n",
    "\n",
    "    #This is the midpoint in the x direction\n",
    "    xm = width/2\n",
    "\n",
    "    #This is the percentage of the image at the 'farthest point'\n",
    "    xtp = 0.079 # larger means narrower\n",
    "\n",
    "    #Calculate the points of the image at the 'farthest point'\n",
    "    xtl = xm - xm * xtp\n",
    "    xtr = xm + xm * xtp\n",
    "\n",
    "    #Set the points of the image at the 'nearest point'\n",
    "    xbl = 0 #640 - 640 * xbp\n",
    "    xbr = width \n",
    "\n",
    "    #Hardcoded vertical section to take; crops the bottom 10% and top 60%\n",
    "    yb = 650 #height*.9 # 648 \n",
    "    yt = 440 #height*.61  # 440 \n",
    "\n",
    "    #Determine the source and dest vertices\n",
    "    vertices = [[(xtl, yt), (xtr, yt), (xbl, yb), (xbr, yb)]]\n",
    "    src_vertices = np.array(vertices, dtype=np.float32)\n",
    "    dest_vertices = np.float32([[0,0],[size,0],[0,size],[size,size]])\n",
    "\n",
    "    #Get the warpping matrix and the inverse warping matrix\n",
    "    M = cv2.getPerspectiveTransform(src_vertices, dest_vertices)\n",
    "    Minv = np.linalg.inv(M)\n",
    "\n",
    "    return M, Minv\n",
    "\n",
    "def warp(img, M, size): \n",
    "    #Warp and return the image per the transformation matrix\n",
    "    warped = cv2.warpPerspective(img, M, size)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def histogram_points(image, pixelsperbin=10):\n",
    "    height = image.shape[0] # 720\n",
    "    width = image.shape[1] # 1280\n",
    "\n",
    "    #Get a histogram of the threshold\n",
    "    #nbins = width/pixelsperbin\n",
    "    histogram = np.sum(image[height*2/3:,:], axis=0)\n",
    "    values = np.asarray(list(range(0, width)))\n",
    "\n",
    "    #Split into left and right halves of histogram\n",
    "    l_histogram = histogram[0:width/2]\n",
    "    r_histogram = histogram[width/2:]\n",
    "\n",
    "    #Split values into left and right\n",
    "    l_values = values[0:width/2]\n",
    "    r_values = values[width/2:]\n",
    "\n",
    "    #Check to make sure we don't have an empty matrix...\n",
    "    l_sum = np.sum(l_histogram)\n",
    "    r_sum = np.sum(r_histogram)\n",
    "\n",
    "    #Get the average of the left and right halves, weighted by the number of hits\n",
    "    if(l_sum > 0):\n",
    "        l_max_index = int(np.average(l_values, weights=l_histogram))\n",
    "    else:\n",
    "        l_max_index = 0\n",
    "\n",
    "    if(r_sum > 0):\n",
    "        r_max_index = int(np.average(r_values, weights=r_histogram))\n",
    "    else:\n",
    "        r_max_index = 0\n",
    "\n",
    "    return l_max_index, r_max_index\n",
    "\n",
    "def run_fit(image, fit, n = 100, margin = 25, left = 0, right = 299):\n",
    "\n",
    "    #Hold on to this for smoothing\n",
    "    old_fit = fit\n",
    "\n",
    "    height = image.shape[0] # 300\n",
    "    width = image.shape[1] # 300\n",
    "\n",
    "    #Lists to hold the points to fit to\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    #For all Y\n",
    "    for y in range(height-1, -1, -1):\n",
    "        #Calculate X\n",
    "        x = int(round(fit[0]*y**2 + fit[1]*y + fit[2]))\n",
    "\n",
    "        #Descending margin with decreasing y\n",
    "        #More likely to find the lane at the bottom\n",
    "        #Less likely to get creative at the top\n",
    "        margin = int(y/6) #50 to 0 for 300 to 0\n",
    "\n",
    "        #Calculate a region of pixels to grab\n",
    "        x_min = x-margin\n",
    "        x_max = x+margin\n",
    "\n",
    "        #Error check the region of pixels\n",
    "        x_min = max(x_min, left)\n",
    "        x_min = min(x_min, right)\n",
    "\n",
    "\n",
    "        x_max = max(x_max, left)\n",
    "        x_max = min(x_max, right)\n",
    "\n",
    "        #Grab the region of pixels\n",
    "        image_sect = image[y,x_min:x_max]\n",
    "\n",
    "        #Get the x coords of those pixels\n",
    "        x_sect = np.where(image_sect==1)\n",
    "        x_sect = x_sect + np.ones_like(x_sect)*x_min\n",
    "\n",
    "        #And the y coords\n",
    "        y_sect = np.ones_like(x_sect)*y\n",
    "\n",
    "        #And add them both to their respective lists\n",
    "        x_list.extend(x_sect.tolist()[0])\n",
    "        y_list.extend(y_sect.tolist()[0])\n",
    "\n",
    "        #If we have a certain number of points\n",
    "        if( len(x_list) > n):\n",
    "            #Use the new 'lane line' to search for the rest of the points\n",
    "            fit = np.polyfit(y_list, x_list, 2)\n",
    "\n",
    "    #Create an image to show which points were used\n",
    "    image_line = np.zeros((300, 300))\n",
    "    for x, y in zip(x_list, y_list):\n",
    "        image_line[y,x] = 1\n",
    "\n",
    "    #Smooth\n",
    "    fit = smooth_fit( fit, old_fit)\n",
    "\n",
    "    return fit, image_line\n",
    "\n",
    "def smooth_fit(new_fit, old_fit, alpha = 0.8):\n",
    "    beta = 1 - alpha\n",
    "    fit = list([n*alpha+o*beta for n,o in zip(new_fit,old_fit)])\n",
    "    return fit\n",
    "\n",
    "#Draws a lane line on an image of specified thickness\n",
    "def make_image_overlay_line( image_overlay, fit, channel = 0, thickness = 5):\n",
    "    y_fit_list =  list(range(300))\n",
    "    x_fit_list = [int(fit[0]*y**2 + fit[1]*y + fit[2]) for y in y_fit_list]\n",
    "    for x, y in zip(x_fit_list, y_fit_list):\n",
    "        if( y > 0 and y < 300 and x > 0 and x < 300):\n",
    "            image_overlay[y-thickness:y+thickness,x-thickness:x+thickness,channel] = 1\n",
    "    return image_overlay\n",
    "\n",
    "#Fills the region between the image\n",
    "def make_image_overlay_fill( image_overlay, l_fit, r_fit):\n",
    "    y_fit_list =  list(range(300))\n",
    "\n",
    "    l_x_fit_list = [int(calcPoint( l_fit, y )) for y in y_fit_list]\n",
    "    r_x_fit_list = [int(calcPoint( r_fit, y )) for y in y_fit_list]\n",
    "\n",
    "    #Get the list of the points for the left and right lane lines\n",
    "    l_fit_points = zip(l_x_fit_list, y_fit_list)\n",
    "    r_fit_points = zip(r_x_fit_list, y_fit_list)\n",
    "\n",
    "    #Loop through and create a list of np array rects to fill\n",
    "    all_rects= []\n",
    "    #Don't draw until the prev_points are set\n",
    "    draw = False\n",
    "    for point1, point2 in zip(list(l_fit_points), list(r_fit_points)):\n",
    "        if draw == True:\n",
    "            #Create a rectangle \n",
    "            rect = np.array([point1, point2, point2_prev, point1_prev])\n",
    "            all_rects.append(rect)\n",
    "        #Current points are saved as the next iteration's previous points\n",
    "        point1_prev = point1\n",
    "        point2_prev = point2\n",
    "        draw = True\n",
    "    cv2.fillPoly(np.asarray(image_overlay), all_rects, (0,1,0))#1)\n",
    "    return image_overlay\n",
    "\n",
    "def make_image_overlay( l_fit, r_fit, thickness = 5):\n",
    "    #Create a blank image\n",
    "    image_overlay = np.zeros((300, 300, 3))\n",
    "    #Draw the left lane line\n",
    "    if( not fitIsZero( l_fit ) ):\n",
    "        image_overlay = make_image_overlay_line(image_overlay, l_fit, channel = 0, thickness=thickness)\n",
    "    #Draw the right lane line\n",
    "    if( not fitIsZero( r_fit ) ):\t\n",
    "        image_overlay = make_image_overlay_line(image_overlay, r_fit, channel = 2, thickness=thickness)\n",
    "    #Fill the middle\n",
    "    if( not fitIsZero( l_fit ) and not fitIsZero( r_fit )):\t\n",
    "        image_overlay = make_image_overlay_fill(image_overlay, l_fit, r_fit)\n",
    "    return image_overlay\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    #print(\"COMPOSITE\")\n",
    "    #print(img.shape)\n",
    "    #print(initial_img.shape)\n",
    "\n",
    "    img = img.astype('uint8')\n",
    "    initial_img = initial_img.astype('uint8')\n",
    "\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def fitIsZero( fit, zero=0.001 ):\n",
    "    #Used to determine if the poly fit is uninitialized\n",
    "    return fit[2] < zero and fit[1] < zero and fit[0] < zero\n",
    "\n",
    "def lineOutOfBounds( fit, y_top = 200, y_bottom = 300, x_left = 1, x_right = 298 ):\n",
    "    #Checking if any part of the line goes out of bounds\n",
    "    #By default, only checks the botom third of the image\n",
    "    for y in range( y_top, y_bottom):\n",
    "        test = pointOutOfBounds( fit, y, x_left, x_right) \n",
    "        if test :\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pointOutOfBounds( fit, y, x_left = 1, x_right = 298 ):\n",
    "\t#Checks to see if point y is out of bounds\n",
    "\tx = calcPoint(fit, y)\n",
    "\tif x < x_left or x > x_right:\n",
    "\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "def calcPoint( fit, y ):\n",
    "\t#Calculates x for y on a given poly fit.\n",
    "\treturn fit[0]*y**2 + fit[1]*y + fit[2]\n",
    "\n",
    "def calcCurve( fit, xm_per_pix = 3.7/700, ym_per_pix = 30/720 ):\n",
    "    #Create y and calculate x\n",
    "    y_fit_list =  list(range(300))\n",
    "    x_fit_list = [int(calcPoint(fit, y)) for y in y_fit_list]\n",
    "\n",
    "    #Convert to meter space from pixel space\n",
    "    y_fit_list_m = [y*ym_per_pix for y in y_fit_list]\n",
    "    x_fit_list_m = [x*xm_per_pix for x in x_fit_list]\n",
    "\n",
    "    # Fit new polynomial to x,y in meter space\n",
    "    fit_m = np.polyfit(y_fit_list_m, x_fit_list_m, 2)\n",
    "\n",
    "    # Calculate the curvature\n",
    "    y = 300 \n",
    "    A = fit_m[0]\n",
    "    B = fit_m[1]\n",
    "    curve=(1+(2*A*y+B)**2)**(3/2)/abs(2*A)\n",
    "\n",
    "    return curve\n",
    "\n",
    "def calcAvgCurve( l_fit, r_fit, xm_per_pix = 3.7/700, ym_per_pix = 30/720 ):\n",
    "\t#Calculate the curvature for the left and right and returns the average\n",
    "\tl_curve = calcCurve(l_fit, xm_per_pix, ym_per_pix)\n",
    "\tr_curve = calcCurve(r_fit, xm_per_pix, ym_per_pix)\n",
    "\treturn ( l_curve + r_curve ) / 2.0\n",
    "\n",
    "def calcLeftRight( l_fit, r_fit, xm_per_pix = 3.7/700 ):\n",
    "\ty = 300\n",
    "\n",
    "\t#Calculate the origin of the left and right lane lines\n",
    "\tl_x = calcPoint(l_fit, y)\n",
    "\tr_x = calcPoint(r_fit, y)\n",
    "\n",
    "\t#Take the median\n",
    "\tx = (l_x + r_x) / 2.0\n",
    "\n",
    "\t#Subtract from 150 (300/2)\n",
    "\tx_offset = x - 150\n",
    "\n",
    "\t#Convert to meter space\n",
    "\tx_offset_m = x_offset * xm_per_pix\n",
    "\n",
    "\treturn x_offset_m\n",
    "\n",
    "def createCurveString(l_fit, r_fit):\n",
    "\t#Calculate and format the curvature string\n",
    "\tcurve = calcAvgCurve( l_fit, r_fit ) \n",
    "\tcurveString = \"Radius of Curvature = \" + \"{0:.1f}\".format(curve) + \" m\"\n",
    "\treturn curveString\n",
    "\n",
    "def createOffsetString(l_fit, r_fit):\n",
    "\t#Calculate and format the offset string\n",
    "\toffset = calcLeftRight( l_fit, r_fit ) \n",
    "\tif (offset < 0):\n",
    "\t\toffset_l_r = \"right\"\n",
    "\telse:\n",
    "\t\toffset_l_r = \"left\"\n",
    "\toffsetString = \"Vehicle is \" + \"{0:.3f}\".format(abs(offset)) + \" m \" + offset_l_r + \" of center\"\n",
    "\treturn offsetString\n",
    "\n",
    "\n",
    "def process( image ):\n",
    "\tglobal r_fit\n",
    "\tglobal l_fit\n",
    "\tglobal objpoints\n",
    "\tglobal imgpoints\n",
    "\n",
    "\t#cv2.imwrite(\"image.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\t\n",
    "\t#Correct for camera lense distortion\n",
    "\timage_undist = undistort( image, objpoints, imgpoints )\n",
    "\t#cv2.imwrite(\"image_undist.jpg\", cv2.cvtColor(image_undist, cv2.COLOR_BGR2RGB) )\n",
    "\t\n",
    "\t#Image analysis - sum of certain channels and gradients\n",
    "\timage_comb = thresh_pipeline( image_undist )\n",
    "\t#cv2.imwrite(\"image_comb.jpg\", image_comb*16)\n",
    "\t\n",
    "\t#Threshold the image\n",
    "\timage_thresh = thresh(image_comb, thresh = (6, 16))\n",
    "\t#cv2.imwrite(\"image_thresh.jpg\", image_thresh*255)\n",
    "\n",
    "\t#Warp the image to the plane of the road\n",
    "\tM, Minv = calcwarp(image_undist, size = 300)\n",
    "\timage_warped = warp(image_thresh, M, (300,300))\n",
    "\t#cv2.imwrite(\"image_warped.jpg\", image_warped*255)\n",
    "\t\n",
    "\t#Use the histogram method to reset if necessary\n",
    "\tl_hist, r_hist = histogram_points(image_warped)\n",
    "\tif(l_fit[0] * r_fit[0] < -1): #Curving opposite directions\n",
    "\t\tr_fit = [0,0,r_hist]\t\n",
    "\t\tl_fit = [0,0,l_hist]\n",
    "\telse:\n",
    "\t\t#Little bit of sanity checking.. If the fits are unititialized or bad, reset\n",
    "\t\tif( lineOutOfBounds(l_fit) ): \n",
    "\t\t\tl_fit = [0,0,l_hist]\n",
    "\t\tif( lineOutOfBounds(r_fit) ):\n",
    "\t\t\tr_fit = [0,0,r_hist]\t\t\n",
    "\n",
    "\t#Use the previous poly fit as guides to calculate the new lane lines\n",
    "\t#Only caveat is - I don't do any smoothing\n",
    "\tl_fit, image_l_fit = run_fit(image_warped, l_fit, 100, 50, 0, 149)\n",
    "\tr_fit, image_r_fit = run_fit(image_warped, r_fit, 100, 50, 150, 299)\n",
    "\t#cv2.imwrite(\"image_l_fit.jpg\", image_l_fit*255)\n",
    "\t#cv2.imwrite(\"image_r_fit.jpg\", image_r_fit*255)\n",
    "\n",
    "\t#Draw the lane lines based on the poly fits\n",
    "\timage_overlay = make_image_overlay( l_fit, r_fit, thickness = 9)\n",
    "\t#cv2.imwrite(\"image_overlay.jpg\", image_overlay*255)\n",
    "\t\n",
    "\t#Unwarp the lane lines back into the plane of the image\n",
    "\timage_overlay_unwarped = warp(image_overlay, Minv, (1280,720))\n",
    "\t#cv2.imwrite(\"image_overlay_unwarped.jpg\", image_overlay_unwarped*255)\n",
    "\t\n",
    "\t#Combine the original image with the unwarped overlay\n",
    "\timage_composite = weighted_img(255*image_overlay_unwarped, image_undist)\n",
    "\t#cv2.imwrite(\"image_composite.jpg\", cv2.cvtColor(image_composite, cv2.COLOR_BGR2RGB))\n",
    "\t\n",
    "\t#Create some text for the HUD and put it on the image\n",
    "\tcurve_string = createCurveString(l_fit, r_fit)\t\n",
    "\toffset_string = createOffsetString(l_fit, r_fit)\n",
    "\timage_text = cv2.putText(image_composite, curve_string, (10,60),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), thickness = 3 )\n",
    "\timage_text = cv2.putText(image_composite, offset_string, (10,120),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), thickness = 3 )\n",
    "\n",
    "\t#Save me an image because I like watching\n",
    "\tcv2.imwrite(\"image_text.jpg\", cv2.cvtColor(image_text, cv2.COLOR_BGR2RGB))\n",
    "\t\n",
    "\treturn image_text\n",
    "\n",
    "\n",
    "# Make a list of calibration images and calibrate\n",
    "calibration_fnames = glob.glob('camera_cal/calibration*.jpg')\n",
    "objpoints, imgpoints = calibrate( calibration_fnames, nx=6, ny=9)\n",
    "\n",
    "# Initialize fit vectors\n",
    "l_fit = [0.0,0.0,0.0]\n",
    "r_fit = [0.0,0.0,0.0]\n",
    "\n",
    "\n",
    "\n",
    "# Make a video!\n",
    "#inputVideoName = \"project_video.mp4\"\n",
    "#inputClip = VideoFileClip(inputVideoName)\n",
    "#outputClip = inputClip.fl_image(process)\n",
    "#outputVideoName = inputVideoName.split('.')[0] + \"_output.mp4\"\n",
    "#outputClip.write_videofile(outputVideoName, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=False, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        #Should just replace all the below with this line...\n",
    "        #single_img_features(image, color_space=color_space, spatial_size=spatial_size,\n",
    "        #                hist_bins=hist_bins, orient=orient, \n",
    "        #                pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "        #                spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=False, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "        \n",
    "        \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=False, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        #print(type(img))\n",
    "        #print(window)\n",
    "        crop_img = img[window[0][1]:window[1][1], window[0][0]:window[1][0]]\n",
    "        test_img = cv2.resize(crop_img, (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "\n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test my process on a few sample images\n",
    "test_fnames = glob.glob('test_images\\\\test?.jpg') \n",
    "#print(test_fnames)\n",
    "#for idx, fname in enumerate( test_fnames ):\n",
    "fname = 'test_images\\\\test1.jpg'\n",
    "image = mpimg.imread( fname )\n",
    "image_undist = undistort( image, objpoints, imgpoints )\n",
    "image_float = np.float32(image_undist)/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car = glob.glob('vehicles/vehicles/*/*.png')\n",
    "notcar = glob.glob('non-vehicles/non-vehicles/*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_space = 'HLS'\n",
    "spatial_size = (32,32)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel='ALL'  \n",
    "\n",
    "##Reviewer Recommendations\n",
    "color_space = 'YCrCb'\n",
    "orient = 11\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\"\n",
    "        \n",
    "car_features = extract_features(car, color_space=color_space, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel)\n",
    "notcar_features = extract_features(notcar, color_space=color_space, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(car_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "if len(car_features) > 0 and len(notcar_features) > 0:\n",
    "    # Create an array stack of feature vectors\n",
    "    #print(len(car_features))\n",
    "       \n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "                           \n",
    "    car_features_scaler = StandardScaler().fit(car_features)\n",
    "    scaled_car_features = car_features_scaler.transform(car_features)\n",
    "    \n",
    "    notcar_features_scaler = StandardScaler().fit(notcar_features)\n",
    "    scaled_notcar_features = notcar_features_scaler.transform(notcar_features)\n",
    "    \n",
    "    #X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    #X_scaler = StandardScaler().fit(X)\n",
    "    #scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot an example of raw and scaled features\n",
    "    #fig = plt.figure(figsize=(12,4))\n",
    "    #plt.subplot(131)\n",
    "    #car_ind = np.random.randint(0, len(car))\n",
    "    #car_image = mpimg.imread(car[car_ind])\n",
    "    #cv2.imwrite(\"car_image.jpg\", cv2.cvtColor(car_image, cv2.COLOR_RGB2BGR) )\n",
    "    #cv2.imwrite(\"car_image.jpg\", car_features )\n",
    "    #notcar_ind = np.random.randint(0, len(notcar))\n",
    "    #notcar_image = mpimg.imread(notcar[notcar_ind])\n",
    "    #cv2.imwrite(\"notcar_image.jpg\", cv2.cvtColor(notcar_image, cv2.COLOR_RGB2BGR) )\n",
    "    #cv2.imwrite(\"car_image.jpg\", notcar_features )\n",
    "    #plt.title('Original Image')\n",
    "    #plt.subplot(132)\n",
    "    #plt.plot(X[car_ind])\n",
    "    #plt.title('Raw Features')\n",
    "    #plt.subplot(133)\n",
    "    #plt.plot(scaled_X[car_ind])\n",
    "    #plt.title('Normalized Features')\n",
    "    #fig.tight_layout()\n",
    "    #plt.show()\n",
    "else: \n",
    "    print('Your function only returns empty feature vectors...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spatial binning of: (32, 32) and 32 histogram bins\n",
      "Feature vector length: 4260\n",
      "7.47 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9884\n",
      "My SVC predicts:  [ 0.  1.  0.  1.  1.  1.  0.  1.  0.  1.]\n",
      "For these 10 labels:  [ 0.  1.  0.  1.  1.  1.  0.  1.  0.  1.]\n",
      "0.035 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# NOTE: the next import is only valid \n",
    "# for scikit-learn version <= 0.17\n",
    "# if you are using scikit-learn >= 0.18 then use this:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using spatial binning of:',spatial_size,\n",
    "    'and', hist_bins,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC(C=0.000100)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4)) # 0.9925\n",
    "# Need to also check kappa and precision and recall\n",
    "\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import math\n",
    "#for Cexp in range(-10,10,1):\n",
    "    #print( Cexp )\n",
    "#    C =  math.pow(10, Cexp)\n",
    "    #print( C )\n",
    "#    svc = LinearSVC(C=C)\n",
    "#    t=time.time()\n",
    "#    svc.fit(X_train, y_train)\n",
    "#    t2 = time.time()\n",
    "    #print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "#    print('With C = ', C,'Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 6)) # 0.9925\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#image = mpimg.imread('bbox-example-image.jpg')\n",
    "\n",
    "\n",
    "\n",
    "#big_windows = slide_window(image_float, x_start_stop=[None, None], y_start_stop=[336, None], \n",
    " #                   xy_window=(128, 128), xy_overlap=(0.8, 0.8))   \n",
    "\n",
    "\n",
    "#window_img = draw_boxes(image_float*255, big_windows, color=(0, 0, 255), thick=3) \n",
    "#cv2.imwrite(\"big_windows.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#hot_windows = search_windows(image_float, big_windows, svc, X_scaler, color_space=color_space, \n",
    "#                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                        cell_per_block=cell_per_block, hog_channel=hog_channel)   \n",
    "\n",
    "#window_img = draw_boxes(image_float*255, hot_windows, color=(0, 0, 255), thick=3)                    \n",
    "#cv2.imwrite(\"big_windows_cars.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#print(len(hot_windows)*1.0/len(big_windows))\n",
    "\n",
    "#med_windows = slide_window(image_float, x_start_stop=[None, None], y_start_stop=[336, None], \n",
    "#                    xy_window=(96, 96), xy_overlap=(0.8, 0.8))   \n",
    "\n",
    "#window_img = draw_boxes(image_float*255, med_windows, color=(0, 0, 255), thick=2)                    \n",
    "#cv2.imwrite(\"med_windows.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#hot_windows = search_windows(image_float, med_windows, svc, X_scaler, color_space=color_space, \n",
    "#                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                        cell_per_block=cell_per_block, hog_channel=hog_channel)   \n",
    "\n",
    "#window_img = draw_boxes(image_float*255, hot_windows, color=(0, 0, 255), thick=2)   \n",
    "#cv2.imwrite(\"med_windows_cars.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#print(len(hot_windows)*1.0/len(med_windows))\n",
    "\n",
    "#small_windows = slide_window(image_float, x_start_stop=[None, None], y_start_stop=[336, None], \n",
    "#                    xy_window=(64, 64), xy_overlap=(0.8, 0.8))   \n",
    "\n",
    "#window_img = draw_boxes(image_float*255, small_windows, color=(0, 0, 255), thick=1)                    \n",
    "#cv2.imwrite(\"small_windows.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#hot_windows = search_windows(image_float, small_windows, svc, X_scaler, color_space=color_space, \n",
    "#                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                        cell_per_block=cell_per_block, hog_channel=hog_channel)    \n",
    "\n",
    "#window_img = draw_boxes(image_float*255, hot_windows, color=(0, 0, 255), thick=1)                    \n",
    "#print(len(hot_windows)*1.0/len(small_windows))\n",
    "\n",
    "#cv2.imwrite(\"small_windows_cars.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#res = cv2.resize(img,None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(type(big_windows))\n",
    "#windows = []\n",
    "#windows.extend(big_windows)\n",
    "#windows.extend(med_windows)\n",
    "#windows.extend(small_windows)\n",
    "#print(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "#  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "#hot_windows = search_windows(image_float, windows, svc, X_scaler, color_space=color_space, \n",
    "#                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                        cell_per_block=cell_per_block, hog_channel=hog_channel)                       \n",
    "#window_img = draw_boxes(image_float*255, hot_windows, color=(0, 0, 255), thick=2)                    \n",
    "\n",
    "#cv2.imwrite(\"windows_cars.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "#heatmap = add_heat(heatmap, hot_windows )\n",
    "#heatmap_thresh = apply_threshold(heatmap, 6) #threshold 5 or less hits\n",
    "##heatmap = heatmap*1.0/np.amax(heatmap)\n",
    "#heatmap_thresh = apply_threshold(heatmap, 0.2) #threshold 20% of the max or less\n",
    "#cv2.imwrite(\"heat_cars.jpg\", heatmap_thresh*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels = label(heatmap)\n",
    "#labelarray = np.asarray(labels[0])\n",
    "#cv2.imwrite(\"label.jpg\", labelarray*255.0/labels[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels = label(heatmap)\n",
    "#bboxes = []\n",
    "#print(labels[1])\n",
    "#for i in range(1, labels[1]+1):\n",
    "    #print(i)\n",
    "    #labelarray = np.asarray(labels[0])\n",
    "#    res = np.where(labelarray==i)\n",
    "#    bbox = ((min(res[1]), min(res[0])), (max(res[1]),  max(res[0])))\n",
    "#    bboxes.append(bbox)\n",
    "    #print(bbox)\n",
    "#print(bboxes)\n",
    "#window_img = draw_boxes(image_float*255, bboxes, color=(0, 0, 255), thick=2)                    \n",
    "#print(len(windows))\n",
    "\n",
    "#print(len(hot_windows)*1.0/len(windows))\n",
    "#cv2.imwrite(\"windows_final.jpg\", cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_windows():\n",
    "    windows = []\n",
    "    y_start = 360\n",
    "    y_stop = 630\n",
    "    big_windows = slide_window(image_float, x_start_stop=[None, None], y_start_stop=[y_start, y_stop], \n",
    "                    xy_window=(112, 112), xy_overlap=(0.8, 0.8))   \n",
    "    windows.extend(big_windows)\n",
    "    \n",
    "    med_windows = slide_window(image_float, x_start_stop=[None, None], y_start_stop=[y_start, y_stop], \n",
    "                    xy_window=(96, 96), xy_overlap=(0.8, 0.8))   \n",
    "    windows.extend(med_windows)\n",
    "    \n",
    "    small_windows = slide_window(image_float, x_start_stop=[None, None], y_start_stop=[y_start, y_stop], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.8, 0.8))   \n",
    "    windows.extend(small_windows)\n",
    "    \n",
    "    return windows\n",
    "\n",
    "prev_heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "alpha = 0.25\n",
    "\n",
    "def get_heatmap( image, windows ):\n",
    "    global prev_heatmap\n",
    "    global alpha\n",
    "    \n",
    "    heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    heatmap = add_heat( heatmap, windows )\n",
    "    heatmap = apply_threshold(heatmap, 3) #threshold 3 or less hits\n",
    "    \n",
    "    if(np.amax(prev_heatmap)<1 or np.amin(prev_heatmap)>1): \n",
    "        #      math.isnan(np.amax(prev_heatmap)) or \n",
    "        #      math.isnan(np.amin(prev_heatmap))):\n",
    "        prev_heatmap = heatmap\n",
    "     \n",
    "    #if(np.amax(heatmap)>0):\n",
    "    #    heatmap = heatmap/np.amax(heatmap)\n",
    "    heatmap = heatmap*(1.0-alpha) \n",
    "    #if(np.amax(prev_heatmap)>0):\n",
    "    #    prev_heatmap = prev_heatmap/np.amax(prev_heatmap)\n",
    "    prev_heatmap = prev_heatmap*alpha\n",
    "    \n",
    "    heatmap = heatmap + prev_heatmap\n",
    "    #print(heatmap)\n",
    "    heatmap = apply_threshold(heatmap, 3) #threshold 3 hits or less \n",
    "\n",
    "    prev_heatmap = heatmap\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def filter_labels(labels, heatmap):\n",
    "    \n",
    "    bboxes = []\n",
    "    labelarray = np.asarray(labels[0])\n",
    "    for i in range(1, labels[1]+1):\n",
    "        \n",
    "        res = np.where(labelarray==i)\n",
    "        x1 = min(res[1])\n",
    "        y1 = min(res[0])\n",
    "        x2 = max(res[1])\n",
    "        y2 = max(res[0])\n",
    "        heatdx = abs(x2-x1)\n",
    "        heatdy = abs(y2-y1)\n",
    "        heatarea = heatdx*heatdy\n",
    "        bbox = ((x1, y1), (x2,  y2))\n",
    "        if(heatdx>10 and heatdy>10):\n",
    "            heatmaparea = heatmap[y1:y2, x1:x2]\n",
    "            heatmax = np.amax(heatmaparea)\n",
    "            heatsum = np.sum(heatmaparea)\n",
    "            heatmean = np.average(heatmaparea, weights=heatmaparea )\n",
    "            #print(i)\n",
    "            #print(heatmax)\n",
    "            #print(heatsum)\n",
    "            #print(heatmean)\n",
    "            #print(heatarea)\n",
    "            if(heatmean>0.05 and heatmax > 0.1):\n",
    "                bboxes.append(bbox)\n",
    "    return bboxes\n",
    "        \n",
    "\n",
    "def test(image):\n",
    "    \n",
    " \n",
    "    color_space = 'HLS'\n",
    "    spatial_size = (32,32)\n",
    "    hist_bins = 32\n",
    "     \n",
    "    #Reviewer Recommendations\n",
    "    color_space = 'YCrCb'\n",
    "    orient = 11\n",
    "    pix_per_cell = 16\n",
    "    cell_per_block = 2\n",
    "    hog_channel = \"ALL\"\n",
    "    \n",
    "    \n",
    "    image_undist = undistort( image, objpoints, imgpoints )\n",
    "    image_float = np.float32(image_undist)/255.\n",
    "     \n",
    "    windows = get_windows( )\n",
    "    \n",
    "    hot_windows = search_windows(image_float, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, hog_channel=hog_channel)  \n",
    "    \n",
    "    window_img_1 = draw_boxes(image_float*255, hot_windows, color=(0, 0, 255), thick=2)                    \n",
    "    cv2.imwrite(\"final_windows.jpg\", cv2.cvtColor(window_img_1, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    heatmap = get_heatmap( image_float, hot_windows )\n",
    "    \n",
    "    heatmapimage = heatmap*255/max(np.amax(heatmap),1)\n",
    "    cv2.imwrite(\"final_heatmap.jpg\", heatmapimage)\n",
    "    \n",
    "    labels = label(heatmap)\n",
    "    labelarray = np.asarray(labels[0])\n",
    "    labelimage = labelarray*255.0/labels[1]\n",
    "    cv2.imwrite(\"final_label.jpg\", labelimage)\n",
    "    \n",
    "    bboxes = filter_labels(labels, heatmap )\n",
    "        \n",
    "    window_img_2 = draw_boxes(image_float*255, bboxes, color=(0, 0, 255), thick=2)                    \n",
    "    cv2.imwrite(\"final_output.jpg\", cv2.cvtColor(window_img_2, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    #a = cv2.cvtColor(window_img_1, cv2.COLOR_BGR2RGB)\n",
    "    #b = cv2.cvtColor(heatmapimage.astype('uint'),cv2.COLOR_GRAY2RGB)\n",
    "    #c = cv2.cvtColor(labelimage,cv2.COLOR_GRAY2RGB)\n",
    "    #d = cv2.cvtColor(window_img_2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #debug_img = np.vstack((a,b,c,d))\n",
    "    #cv2.imwrite(\"final_debug.jpg\", debug_img)\n",
    "    \n",
    "    return window_img_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alpha = 0\n",
    "# Test my process on a few sample images\n",
    "#test_fnames = glob.glob('test_images\\\\test?.jpg') \n",
    "#print(test_fnames)\n",
    "#for idx, fname in enumerate( test_fnames ):\n",
    "fname = 'test_images\\\\test1.jpg'\n",
    "    #print(fname)\n",
    "image = mpimg.imread( fname )\n",
    "    #image_output = test(image)\n",
    "image_undist = undistort( image, objpoints, imgpoints )\n",
    "image_float = np.float32(image_undist)/255.\n",
    "     \n",
    "windows = get_windows( )\n",
    "    \n",
    "hot_windows = search_windows(image_float, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, hog_channel=hog_channel)  \n",
    "    \n",
    "window_img_1 = draw_boxes(image_float*255, hot_windows, color=(0, 0, 255), thick=2)                    \n",
    "cv2.imwrite(\"final_windows.jpg\", cv2.cvtColor(window_img_1, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "heatmap = get_heatmap( image_float, hot_windows )\n",
    "heatmapimage = heatmap*255/np.amax(heatmap)\n",
    "cv2.imwrite(\"final_heatmap.jpg\", heatmapimage)\n",
    "    \n",
    "labels = label(heatmap)\n",
    "labelarray = np.asarray(labels[0])\n",
    "labelimage = labelarray*255.0/labels[1]\n",
    "cv2.imwrite(\"final_label.jpg\", labelimage)\n",
    "\n",
    "bboxes = filter_labels(labels, heatmap )\n",
    "\n",
    "window_img_2 = draw_boxes(image_float*255, bboxes, color=(0, 0, 255), thick=2)                    \n",
    "cv2.imwrite(\"final_output.jpg\", cv2.cvtColor(window_img_2, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    #a = cv2.cvtColor(window_img_1, cv2.COLOR_BGR2RGB)\n",
    "    #b = cv2.cvtColor(heatmapimage.astype('uint'),cv2.COLOR_GRAY2RGB)\n",
    "    #c = cv2.cvtColor(labelimage,cv2.COLOR_GRAY2RGB)\n",
    "    #d = cv2.cvtColor(window_img_2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #debug_img = np.vstack((a,b,c,d))\n",
    "    #cv2.imwrite(\"final_debug.jpg\", debug_img)\n",
    "    \n",
    "    #return window_img_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_video_output_new_4.mp4\n",
      "[MoviePy] Writing video test_video_output_new_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/39 [00:00<?, ?it/s]\n",
      "  3%|█                                          | 1/39 [00:27<17:19, 27.37s/it]\n",
      "  5%|██▏                                        | 2/39 [00:55<16:55, 27.45s/it]\n",
      "  8%|███▎                                       | 3/39 [01:28<17:33, 29.26s/it]\n",
      " 10%|████▍                                      | 4/39 [01:59<17:21, 29.76s/it]\n",
      " 13%|████▌                               | 5/39 [6:10:51<62:54:16, 6660.49s/it]\n",
      " 15%|█████▌                              | 6/39 [6:11:21<42:49:12, 4671.29s/it]\n",
      " 18%|██████▍                             | 7/39 [6:11:48<29:08:13, 3277.92s/it]\n",
      " 21%|███████▍                            | 8/39 [6:12:14<19:49:36, 2302.45s/it]\n",
      " 23%|████████▎                           | 9/39 [6:12:43<13:30:13, 1620.44s/it]\n",
      " 26%|█████████▏                          | 10/39 [6:13:23<9:14:01, 1146.27s/it]\n",
      " 28%|██████████▍                          | 11/39 [6:14:00<6:19:36, 813.44s/it]\n",
      " 31%|███████████▍                         | 12/39 [6:14:32<4:20:35, 579.10s/it]\n",
      " 33%|████████████▎                        | 13/39 [6:15:00<2:59:20, 413.85s/it]\n",
      " 36%|█████████████▎                       | 14/39 [6:15:39<2:05:28, 301.15s/it]\n",
      " 38%|██████████████▏                      | 15/39 [6:16:12<1:28:17, 220.74s/it]\n",
      " 41%|███████████████▏                     | 16/39 [6:16:41<1:02:33, 163.19s/it]\n",
      " 44%|█████████████████                      | 17/39 [6:17:12<45:20, 123.64s/it]\n",
      " 46%|██████████████████▍                     | 18/39 [6:17:39<33:09, 94.73s/it]\n",
      " 49%|███████████████████▍                    | 19/39 [6:18:06<24:46, 74.34s/it]\n",
      " 51%|████████████████████▌                   | 20/39 [6:18:34<19:05, 60.30s/it]\n",
      " 54%|█████████████████████▌                  | 21/39 [6:19:03<15:18, 51.02s/it]\n",
      " 56%|██████████████████████▌                 | 22/39 [6:19:28<12:14, 43.21s/it]\n",
      " 59%|███████████████████████▌                | 23/39 [6:19:55<10:13, 38.32s/it]\n",
      " 62%|████████████████████████▌               | 24/39 [6:20:27<09:06, 36.41s/it]\n",
      " 64%|█████████████████████████▋              | 25/39 [6:20:59<08:13, 35.25s/it]\n",
      " 67%|██████████████████████████▋             | 26/39 [6:21:32<07:28, 34.49s/it]\n",
      " 69%|███████████████████████████▋            | 27/39 [6:22:02<06:37, 33.09s/it]\n",
      " 72%|████████████████████████████▋           | 28/39 [6:22:32<05:55, 32.32s/it]\n",
      " 74%|█████████████████████████████▋          | 29/39 [6:23:05<05:25, 32.52s/it]\n",
      " 77%|██████████████████████████████▊         | 30/39 [6:23:32<04:35, 30.66s/it]\n",
      " 79%|███████████████████████████████▊        | 31/39 [6:24:00<03:59, 29.95s/it]\n",
      " 82%|████████████████████████████████▊       | 32/39 [6:24:31<03:32, 30.35s/it]\n",
      " 85%|█████████████████████████████████▊      | 33/39 [6:25:02<03:02, 30.45s/it]\n",
      " 87%|██████████████████████████████████▊     | 34/39 [6:25:37<02:38, 31.73s/it]\n",
      " 90%|███████████████████████████████████▉    | 35/39 [6:26:06<02:04, 31.01s/it]\n",
      " 92%|████████████████████████████████████▉   | 36/39 [6:26:33<01:29, 29.74s/it]\n",
      " 95%|█████████████████████████████████████▉  | 37/39 [6:26:59<00:57, 28.64s/it]\n",
      " 97%|██████████████████████████████████████▉ | 38/39 [6:27:25<00:27, 27.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_video_output_new_4.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prev_heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "inputVideoName = \"test_video.mp4\"\n",
    "inputClip = VideoFileClip(inputVideoName)\n",
    "outputClip = inputClip.fl_image(test)\n",
    "outputVideoName = inputVideoName.split('.')[0] + \"_output_final.mp4\"\n",
    "outputClip.write_videofile(outputVideoName, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output_new_4.mp4\n",
      "[MoviePy] Writing video project_video_output_new_4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                 | 0/1261 [00:00<?, ?it/s]\n",
      "  0%|                                       | 1/1261 [00:25<9:04:16, 25.92s/it]\n",
      "  0%|                                       | 2/1261 [00:56<9:34:52, 27.40s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-698ec873c798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputClip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputClip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutputVideoName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputVideoName\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_output_new_4.mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutputClip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputVideoName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params)\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-172>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params)\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-171>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params)\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params)\u001b[0m\n\u001b[1;32m    337\u001b[0m                            \u001b[0maudiofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudiofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                            ffmpeg_params=ffmpeg_params)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     for t,frame in clip.iter_frames(progress_bar=True, with_times=True,\n\u001b[0;32m--> 204\u001b[0;31m                                     fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[1;31m# Update and print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-136>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \"\"\"\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-457c0fd2950f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    101\u001b[0m                         \u001b[0mspatial_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspatial_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhist_bins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpix_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpix_per_cell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                         cell_per_block=cell_per_block, hog_channel=hog_channel)  \n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mwindow_img_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_float\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhot_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthick\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b5ab329c1fb7>\u001b[0m in \u001b[0;36msearch_windows\u001b[0;34m(img, windows, clf, scaler, color_space, spatial_size, hist_bins, hist_range, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\u001b[0m\n\u001b[1;32m    174\u001b[0m                             \u001b[0mcell_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                             \u001b[0mhog_channel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhog_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspatial_feat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                             hist_feat=hist_feat, hog_feat=hog_feat)\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[1;31m#5) Scale extracted features to be fed to classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b5ab329c1fb7>\u001b[0m in \u001b[0;36msingle_img_features\u001b[0;34m(img, color_space, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 hog_features.extend(get_hog_features(feature_image[:,:,channel], \n\u001b[1;32m    141\u001b[0m                                     \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpix_per_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                     vis=False, feature_vec=True))      \n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
      "\u001b[0;32m<ipython-input-2-b5ab329c1fb7>\u001b[0m in \u001b[0;36mget_hog_features\u001b[0;34m(img, orient, pix_per_cell, cell_per_block, vis, feature_vec)\u001b[0m\n\u001b[1;32m     20\u001b[0m                        \u001b[0mcells_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_per_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                        \u001b[0mtransform_sqrt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                        visualise=vis, feature_vector=feature_vec)\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\moellers\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py\u001b[0m in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, visualise, transform_sqrt, feature_vector, normalise)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     _hoghistogram.hog_histograms(gx, gy, cx, cy, sx, sy, n_cellsx, n_cellsy,\n\u001b[0;32m--> 140\u001b[0;31m                                  orientations, orientation_histogram)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[1;31m# now for each cell, compute the histogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "prev_heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "inputVideoName = \"project_video.mp4\"\n",
    "inputClip = VideoFileClip(inputVideoName)#.subclip(10, 11)\n",
    "outputClip = inputClip.fl_image(test)\n",
    "outputVideoName = inputVideoName.split('.')[0] + \"_output_final.mp4\"\n",
    "outputClip.write_videofile(outputVideoName, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import data, color, exposure\n",
    "car_ind = np.random.randint(0, len(car))\n",
    "car_image = mpimg.imread(car[car_ind])\n",
    "#print(type(car_image))\n",
    "#print(car_image.shape)\n",
    "car_image_hls = cv2.cvtColor(car_image, cv2.COLOR_RGB2HLS)\n",
    "for channel in range(car_image_hls.shape[2]):\n",
    "    fd, hog_car_image = hog(car_image_hls[:,:,channel], orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=True, feature_vector=False)\n",
    "    #print(hog_car_image)\n",
    "    hog_car_image_rescaled = exposure.rescale_intensity(hog_car_image, in_range=(0, 255))\n",
    "    #print(hog_car_image_rescaled)\n",
    "    cv2.imwrite(\"hog_car_image_\"+str(channel)+\".jpg\", hog_car_image*255/np.amax(hog_car_image))\n",
    "    \n",
    "from skimage import data, color, exposure\n",
    "car_ind = np.random.randint(0, len(notcar))\n",
    "car_image = mpimg.imread(notcar[car_ind])\n",
    "#print(type(car_image))\n",
    "#print(car_image.shape)\n",
    "car_image_hls = cv2.cvtColor(car_image, cv2.COLOR_RGB2HLS)\n",
    "for channel in range(car_image_hls.shape[2]):\n",
    "    fd, hog_car_image = hog(car_image_hls[:,:,channel], orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=True, feature_vector=False)\n",
    "    #print(hog_car_image)\n",
    "    hog_car_image_rescaled = exposure.rescale_intensity(hog_car_image, in_range=(0, 255))\n",
    "    #print(hog_car_image_rescaled)\n",
    "    cv2.imwrite(\"hog_notcar_image_\"+str(channel)+\".jpg\", hog_car_image*255/np.amax(hog_car_image))\n",
    "    \n",
    "    #cv2.imwrite(\"car_image.jpg\", cv2.cvtColor(car_image, cv2.COLOR_RGB2BGR) )\n",
    "    #cv2.imwrite(\"car_image.jpg\", car_features )\n",
    "    #notcar_ind = np.random.randint(0, len(notcar))\n",
    "    #notcar_image = mpimg.imread(notcar[notcar_ind])\n",
    "    #cv2.imwrite(\"notcar_image.jpg\", cv2.cvtColor(notcar_image, cv2.COLOR_RGB2BGR) )\n",
    "    #cv2.imwrite(\"car_image.jpg\", notcar_features )\n",
    "    #plt.title('Original Image')\n",
    "    #plt.subplot(132)\n",
    "    #plt.plot(X[car_ind])\n",
    "    #plt.title('Raw Features')\n",
    "    #plt.subplot(133)\n",
    "    #plt.plot(scaled_X[car_ind])\n",
    "    #plt.title('Normalized Features')\n",
    "    #fig.tight_layout()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
